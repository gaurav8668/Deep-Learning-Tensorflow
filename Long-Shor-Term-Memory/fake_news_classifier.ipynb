{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "26ff94c46bdf132d8109c8afe01a0a8958f57be37d39acba2c4dfb8035f7c501"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>Darrell Lucus</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n      <td>Daniel J. Flynn</td>\n      <td>Ever get the feeling your life circles the rou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why the Truth Might Get You Fired</td>\n      <td>Consortiumnews.com</td>\n      <td>Why the Truth Might Get You Fired October 29, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n      <td>Jessica Purkiss</td>\n      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian woman jailed for fictional unpublished...</td>\n      <td>Howard Portnoy</td>\n      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\jgaur\\Tensorflow_Tut\\LSTM\\fake-news\\train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nan values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the independent fetures\n",
    "\n",
    "X = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dependent features\n",
    "\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18285, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from  tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)  # bcz we have droped the Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jgaur\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n",
    "    review = review.lower()\n",
    "    # print(review[:5])\n",
    "    review = review.split()\n",
    "    # print(review[:5])\n",
    "    review = [word for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = [one_hot(word, voc_size) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    0    0 ... 4180  498 4163]\n [   0    0    0 ...  683 3960 1313]\n [   0    0    0 ... 3920 4857 3950]\n ...\n [   0    0    0 ... 2928  833 1776]\n [   0    0    0 ...  489 4089 2476]\n [   0    0    0 ... 4747 3494 1277]]\n"
     ]
    }
   ],
   "source": [
    "sen_length = 25\n",
    "pad_sequence = pad_sequences(one_hot, padding='pre', maxlen=sen_length)\n",
    "print(pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 25, 40)            200000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 100)               56400     \n_________________________________________________________________\ndense (Dense)                (None, 1)                 101       \n=================================================================\nTotal params: 256,501\nTrainable params: 256,501\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sen_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile tell the model what loss and optimization mehtod to use\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18285,)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "X_final = np.array(pad_sequence)\n",
    "y_final = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 14s 72ms/step - loss: 0.3297 - accuracy: 0.8440 - val_loss: 0.1948 - val_accuracy: 0.9163\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 9s 49ms/step - loss: 0.1340 - accuracy: 0.9473 - val_loss: 0.1983 - val_accuracy: 0.9171\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.2413 - val_accuracy: 0.9193\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 10s 51ms/step - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.2742 - val_accuracy: 0.9152\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 13s 70ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.3694 - val_accuracy: 0.9089\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 11s 60ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.4407 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 10s 52ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.4791 - val_accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.5495 - val_accuracy: 0.9012\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.5847 - val_accuracy: 0.9107\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6227 - val_accuracy: 0.9142\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sen_length))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  }
 ]
}